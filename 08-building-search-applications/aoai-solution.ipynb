{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the following noteboooks, if you haven't done yet, you need to deploy a model that uses `text-embedding-ada-002` as base model and set the deployment name inside .env file as `AZURE_OPENAI_EMBEDDINGS_ENDPOINT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "model = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to load the Embedding Index into a Pandas Dataframe. The Embedding Index is stored in a JSON file called `embedding_index_3m.json`. The Embedding Index contains the Embeddings for each of the YouTube transcripts up until late Oct 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>title</th>\n",
       "      <th>videoId</th>\n",
       "      <th>start</th>\n",
       "      <th>seconds</th>\n",
       "      <th>summary</th>\n",
       "      <th>ada_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Join Seth Juarez as he discusses ethical conce...</td>\n",
       "      <td>[0.004357332363724, -0.028409153223037, 0.0111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:03:07</td>\n",
       "      <td>187</td>\n",
       "      <td>In this video, the speaker discusses the chall...</td>\n",
       "      <td>[-0.0038613036740570003, -0.004626247566193000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:06:13</td>\n",
       "      <td>373</td>\n",
       "      <td>The video discusses the limitations of general...</td>\n",
       "      <td>[0.00287682027556, -0.012365541420876001, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:09:21</td>\n",
       "      <td>561</td>\n",
       "      <td>The video discusses the importance of consider...</td>\n",
       "      <td>[0.015913352370262, 0.000721095071639, 0.02349...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:12:24</td>\n",
       "      <td>744</td>\n",
       "      <td>The video discusses the importance of understa...</td>\n",
       "      <td>[5.447878720588051e-06, -0.011837740428745, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 speaker  \\\n",
       "0  Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "1  Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "2  Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "3  Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "4  Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "\n",
       "                                               title      videoId     start  \\\n",
       "0  You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s  00:00:00   \n",
       "1  You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s  00:03:07   \n",
       "2  You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s  00:06:13   \n",
       "3  You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s  00:09:21   \n",
       "4  You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s  00:12:24   \n",
       "\n",
       "   seconds                                            summary  \\\n",
       "0        0  Join Seth Juarez as he discusses ethical conce...   \n",
       "1      187  In this video, the speaker discusses the chall...   \n",
       "2      373  The video discusses the limitations of general...   \n",
       "3      561  The video discusses the importance of consider...   \n",
       "4      744  The video discusses the importance of understa...   \n",
       "\n",
       "                                              ada_v2  \n",
       "0  [0.004357332363724, -0.028409153223037, 0.0111...  \n",
       "1  [-0.0038613036740570003, -0.004626247566193000...  \n",
       "2  [0.00287682027556, -0.012365541420876001, 0.02...  \n",
       "3  [0.015913352370262, 0.000721095071639, 0.02349...  \n",
       "4  [5.447878720588051e-06, -0.011837740428745, 0....  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to create a function called `get_videos` that will search the Embedding Index for the query. The function will return the top 5 videos that are most similar to the query. The function works as follows:\n",
    "\n",
    "1. First, a copy of the Embedding Index is created.\n",
    "2. Next, the Embedding for the query is calculated using the OpenAI Embedding API.\n",
    "3. Then a new column is created in the Embedding Index called `similarity`. The `similarity` column contains the cosine similarity between the query Embedding and the Embedding for each video segment.\n",
    "4. Next, the Embedding Index is filtered by the `similarity` column. The Embedding Index is filtered to only include videos that have a cosine similarity greater than or equal to 0.75.\n",
    "5. Finally, the Embedding Index is sorted by the `similarity` column and the top 5 videos are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), \"constant\")\n",
    "    elif len(b) > len(a):\n",
    "        a = np.pad(a, (0, len(b) - len(a)), \"constant\")\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query\n",
    "    query_embeddings = (\n",
    "        client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "    )\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is very simple, it just prints out the results of the search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, the Embedding Index is loaded into a Pandas Dataframe.\n",
    "2. Next, the user is prompted to enter a query.\n",
    "3. Then the `get_videos` function is called to search the Embedding Index for the query.\n",
    "4. Finally, the `display_results` function is called to display the results to the user.\n",
    "5. The user is then prompted to enter another query. This process continues until the user enters `exit`.\n",
    "\n",
    "![](../images/notebook-search.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "You will be prompted to enter a query. Enter a query and press enter. The application will return a list of videos that are relevant to the query. The application will also return a link to the place in the video where the answer to the question is located.\n",
    "\n",
    "Here are some queries to try out:\n",
    "\n",
    "- What is Azure Machine Learning?\n",
    "- How do convolutional neural networks work?\n",
    "- What is a neural network?\n",
    "- Can I use Jupyter Notebooks with Azure Machine Learning?\n",
    "- What is ONNX?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Videos similar to 'vector databases':\n",
      " - Distributed Processing\n",
      "   Summary: In this video, the presenter demonstrates how to manage data in Azure storage service as...\n",
      "   YouTube: https://youtu.be/CoIhbHT2uKQ?t=184\n",
      "   Similarity: 0.7807777907538289\n",
      "   Speakers: Mei\n",
      " - Azure ML Data Prep GUI, Its Not Just About The Code\n",
      "   Summary: The video demonstrates a data preparation tool called Microsoft Data Prep User Interface. It uses...\n",
      "   YouTube: https://youtu.be/CbH0X7Tndas?t=912\n",
      "   Similarity: 0.7748082666208614\n",
      "   Speakers: Azure ML Data Prep GUI, Its Not Just About The Code\n",
      " - Setting Up Azure ML Services and Data Wrangling Using Azure ML Services [Part 2/4]\n",
      "   Summary: The video demonstrates how to use a data preparation tool in Azure to clean and...\n",
      "   YouTube: https://youtu.be/iyCSZ86s5J0?t=187\n",
      "   Similarity: 0.7687766452240409\n",
      "   Speakers: AI Show\n",
      " - Automated Machine Learning on Azure\n",
      "   Summary: To predict customer subscriptions to fixed bank deposits, an experiment is conducted using data and...\n",
      "   YouTube: https://youtu.be/I8m4kZIeHJ4?t=182\n",
      "   Similarity: 0.7653986853659883\n",
      "   Speakers: Kiana, Seth\n",
      " - Azure Machine Learning Datasets\n",
      "   Summary: In this video, the speaker explains how to create and use datasets in Azure Machine...\n",
      "   YouTube: https://youtu.be/a2GXKyfgQjA?t=183\n",
      "   Similarity: 0.764334009977092\n",
      "   Speakers: Mae\n"
     ]
    }
   ],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
